---
author: "Matthew Arsenault and Kelvin Bacelli"
title: "Your descriptive title"
date: "2025-10-08"
output:
  pdf_document:
    number_sections: true
---
```{r echo=FALSE, include=FALSE, message=FALSE}
# all library load statements here
library(caret)
library(knitr)
r.version <- "4.3.2"
seed.val <- 123456
```

Note: Brief intro and your main question go in this space. You may edit the headings and outline as fits your analysis. 

# Data Description and Processing

The dataset we used was compiled by the used auto industry and contains information related to the sale of pre-owned vehicles. The data provide insights into various attributes of used cars that may influence their selling price.

This dataset contains several types of observations describing vehicle characteristics and ownership details for a range of car listings.

Outcomes:\
selling_price: Selling price of the vehicle (in U.S. dollars). \\
Vehicle Attributes:\
km_driven: Total distance the car has been driven (in kilometers).\
mileage: Fuel efficiency of the vehicle (in miles per gallon).\
engine: Engine capacity (in cubic centimeters).\
max_power: Maximum power output of the vehicle (in brake horsepower).\
seats: Number of seats available in the car. \
transmission: Type of transmission, either manual or automatic.\
Ownership:\
seller_type: Indicates whether the seller is an individual or a dealer.\
owner: Level of ownership - First Owner, Second Owner, Third Owner, or Fourth & Above Owner. \

The dataset was examined for missing values. Of the original 3,425 rows, 111 contained one or more missing entries. These 111 rows were removed, leaving a total of 3,314 complete observations for analysis.

```{r echo=FALSE, include=FALSE}
data.df <- read.csv("dataset3.csv")
data.df <- na.omit(data.df)
data.df$transmission <- factor(data.df$transmission)
data.df$owner <- factor(data.df$owner)
data.df$seller_type <- factor(data.df$seller_type)
```
# Data Exploration

The dataset contains observations on used cars with varying numbers of previous owners. Since vehicle ownership history is likely to influence selling price, we compare the number of vehicles across ownership levels. The distribution shows that most cars are first-owner vehicles(~66%), with progressively fewer cars in each subsequent ownership category.

```{r echo=FALSE}
label = c("First Owner","Second Owner", "Third Owner","Fourth & Above Owner")
count = c("2204","801","233","76")
owner.tbl <- cbind(label,count)
kable(owner.tbl, caption = "Owner Comparison")
```

We also explored the distribution of our outcome variable, selling price, to understand the overall spread of car values in the dataset. The distribution is heavily right-skewed, indicating that while most vehicles sell for relatively low prices, a small number of cars have very high selling prices.

```{r echo=FALSE, out.width="60%", out.height="40%", fig.align = 'center', fig.cap="Selling Price (US dollars)."}
hist(data.df$selling_price, freq = FALSE, main = "", xlab = "Value",ylab = "Density")

lines(density(data.df$selling_price),col = "red",lwd=2)
```


```{r echo=FALSE}
# table of descriptive stats for the overall life expectancy
Statistics <- c("Min", "Mean","Median","StdDev","Max")
mn<-min(data.df$selling_price)
mx<-max(data.df$selling_price)
avg<-round(mean(data.df$selling_price), 2)
md<-median(data.df$selling_price)
std<-round(sd(data.df$selling_price), 2)
Value <- c(mn,avg,md,std,mx)
st.tbl <- cbind(Statistics, Value)
kable(st.tbl, caption="Overall Selling Price Descriptive Stats")
```

Due to the fact that the original selling price variable was highly right-skewed, we applied the natural logarithm to the graph in order to make the distribution more symmetric. This helps stabilize the variance and makes the data more suitable for statistical modeling techniques (which assume approximately normal residuals). Because the natural log scale is exponential, each one-unit increase in log(selling price) corresponds to roughly a 2.7x increase in the actual selling price, meaning values from 10 to 11 represent about a 2.7 times increase, and from 11 to 12 another 2.7 times increase.

```{r echo=FALSE, out.width="60%", out.height="40%", fig.align = 'center', fig.cap="Selling Price (US dollars)."}

hist(log(data.df$selling_price), freq = FALSE, main = "", xlab = "Log(Selling Price)",ylab = "Density")

lines(density(log(data.df$selling_price)),col = "red",lwd=2)


```

We created a boxplot of the log-transformed selling price across the four ownership categories to explore how the number of previous owners affects vehicle value. As shown in the plot, as the ownership level increases, the mean selling price decreases, indicating that vehicles with more previous owners tend to have lower market values.

```{r echo=FALSE, out.width="60%", out.height="40%", fig.align = 'center', fig.cap="Selling Price by Ownership Level."}
data.df$owner <- trimws(data.df$owner)  # remove any stray spaces

data.df$owner <- factor(data.df$owner,levels = c("First Owner", "Second Owner", "Third Owner", "Fourth & Above Owner"))

par(mar = c(8,4,4,2))
boxplot(log(selling_price)~owner,data = data.df,main="",ylab = "Log(Selling Price)", xlab = "Level of Ownership", las=1,cex.axis=0.8)

```
```{r echo=FALSE}
# table of descriptive stats for the overall life expectancy
statistics <- c("Min", "Mean","Median","StdDev","Max")
#developed
data1<-first.df$selling_price
mn1<-min(data1)
mx1<-max(data1)
avg1<-round(mean(data1), 2)
md1<-median(data1)
std1<-round(sd(data1), 2)
first <- c(mn1,avg1,md1,std1,mx1)
#developing
data2<-second.df$selling_price
mn2<-min(data2)
mx2<-max(data2)
avg2<-round(mean(data2), 2)
md2<-median(data2)
std2<-round(sd(data2), 2)
second <- c(mn2,avg2,md2,std2,mx2)

data3<-third.df$selling_price
mn3<-min(data3)
mx3<-max(data3)
avg3<-round(mean(data3), 2)
md3<-median(data3)
std3<-round(sd(data3), 2)
third <- c(mn3,avg3,md3,std3,mx3)

data4<-fourth.df$selling_price
mn4<-min(data4)
mx4<-max(data4)
avg4<-round(mean(data4), 2)
md4<-median(data4)
std4<-round(sd(data4), 2)
fourth <- c(mn4,avg4,md4,std4,mx4)

tble.df<- data.frame(statistic, first, second, third, fourth)
kable(tble.df, caption="Selling Price per Status Descriptive Stats")

```

A one-way ANOVA was conducted to test whether mean log(selling_price) differed across ownership levels. The results were highly significant, meaning at least one group differed from the others. A Tukey post-hoc test revealed that all pairwise comparisons between ownership levels were statistically significant (p<0.001), further reinforcing the trend that car value decreases as the number of previous owners increases.

```{r echo=FALSE, include=FALSE} 
anova_result <- aov(log(selling_price)~owner,data = data.df)
TukeyHSD(anova_result)
```
# Modeling 

The variable selling_price represents the outcome of interest - the market value (US Dollars) of a used vehicle. Predictor variables such as year and km_driven reflect the vehicle's age and usage, while fuel, seller_type, and transmission describe its technical and commercial characteristics. The variable owner captures ownership history, which may indicate how well the car was maintained. Together, these predictors represent both physical wear and market perception factors that could affect resale value. Exploring their relationship with selling price can reveal which characteristics most strongly determine how much a vehicle sells for.

## Hypothesis

We believe that the selling price of used cars will be positively correlated with the lower amount of kilometers driven and fewer amount of previous owners. Additionally, we expect a positive correlation with the higher mileage efficiency, a greater number of seats, a higher maximum power, and a larger engine size.k dd

## Model 1:

We fit a linear model selling_price as our outcome variable and the predictor variables km_driven, seller_type, transmission, owner, mileage, engine, max_power, and seats to mainly get a better idea of what values are more significant than others. The results are as followed:

```{r echo=FALSE}
fit.all <- lm(selling_price ~ km_driven+seller_type+transmission+owner+mileage+engine+max_power+seats, data = data.df)
vals <- coef(summary(fit.all))
colnames(vals)[4] <- "p value"
vals <- round(vals, 4)
kable(vals)
```

The adjusted R-squared value for this model was 0.6747, meaning that around 67.5% of the variation of selling price can be explained by the predictors included in the model. This suggests that this model has a reasonably good fit.

The following is a residual histogram and a Q-Q plot to show how closely your residuals follow a normal distribution. The histogram displays a strong peak at the center with evident skewness and a few big outliers. The same is also reflected in the Q-Q plot, indicating that the model is not perfectly normal.

```{r echo=FALSE, out.width="60%", out.height="40%", fig.align = 'center', fig.cap="Distribution of Residuals: Model 1."}
par(mfrow=c(1,2))
hist(fit.all$residuals, freq = FALSE, main = "", xlab = "Residuals", xlim = range(fit.all$residuals), ylim = c(0, max(density(fit.all$residuals)$y) * 1.1))
lines(density(fit.all$residuals), lwd = 2)


qqnorm(y=fit.all$residuals, main = "")
qqline(y=fit.all$residuals, datax = FALSE)
```

After examining our data, we found that cars with higher fuel efficiency, greater engine power, and more seats tended to sell for higher prices, while cars with more kilometers driven, manual transmissions, individual sellers, and multiple previous owners were associated with lower prices. Notably, second and third-owner vehicles were cheaper than first-owner cars, whereas having four or more previous owners did not significantly affect price (p = 0.4383). Similarly, although the number of seats generally increased in value, its effect was less pronounced in some cases. 

## Model 2:

The data contains observations from a variety of cars with different specifications and ownership histories. There may be significant differences in how mileage, engine size, power, and other characteristics impact the selling price depending on the type of seller, transmission, and ownership status.

We fit a second linear model that included all of the above predictors with the exception of seats because it had the highest p-value (least significant).

```{r echo=FALSE}
fit.seven <- lm(selling_price ~ km_driven+seller_type+transmission+owner+mileage+engine+max_power, data = data.df)
seven.vals <- coef(summary(fit.seven))
colnames(seven.vals)[4] <- "p value"
seven.vals <- round(seven.vals, 4)
kable(seven.vals)
```

The adjusted R-squared value for this model was 0.6742, meaning that around 67.42% of the variation of selling price can be explained by the predictors included in the model. This is slightly lower than the previous model and is likely caused by the fact that even though we removed the least significant predictor, seats still had a p-value of ~0.02 which is considered highly significant (since it's less than 0.05).

The following is a residual histogram and a Q-Q plot to show how closely our residuals follow a normal distribution. The histogram displays a strong peak about the center with evident skewness and a few big outliers. The same is also reflected in the Q-Q plot, although this this model follows the line a bit more loosely, making it slightly less normal than model 1.

```{r echo=FALSE, out.width="60%", out.height="40%", fig.align = 'center', fig.cap="Distribution of Residuals: Model 1."}
par(mfrow=c(1,2))
hist(fit.seven$residuals, freq = FALSE, main = "", xlab = "Residuals", xlim = range(fit.seven$residuals), ylim = c(0, max(density(fit.seven$residuals)$y) * 1.1))
lines(density(fit.seven$residuals), lwd = 2)


qqnorm(y=fit.seven$residuals, main = "")
qqline(y=fit.seven$residuals, datax = FALSE)
```

Overall, model 2 affirms the conclusions reached from model 1, that being, cars with higher fuel efficiency, greater engine power, and more seats tended to sell for higher prices, while cars with more kilometers driven, manual transmissions, individual sellers, and multiple previous owners were associated with lower prices.

# Predicting with Models 1 and 2

Now that we have two distinct models, we can work with both of them to see which one is a better predictor of selling price given data. We can use a 10-fold cross validation to do this, seperating 80% of the data to use for training, and the other 20% for testing on each fold.

```{r echo=FALSE}
train.control <- trainControl(method = "cv", number = 10, p = 0.80) 
RNGversion(r.version)
set.seed(seed.val)

all.train <- train(selling_price ~ km_driven+seller_type+transmission+owner+mileage+engine+max_power+seats, data = data.df, method = "lm", trControl = train.control)
log.train <- train(log(selling_price) ~ log(km_driven)+seller_type+transmission+owner+mileage+engine+max_power+seats, data = data.df, method = "lm", trControl = train.control)
```


```{r echo=FALSE, out.width="60%", out.height="40%", fig.align = 'center', fig.cap="RMSE Over 10 Folds."}
num.folds <- 10
rmse.all <- all.train$resample$RMSE
rmse.log <- log.train$resample$RMSE
plot(rmse.all, xlab = "Fold", xaxp = c(1, num.folds, num.folds-1), ylab = "RMSE", ylim=c(min(rmse.log), max(rmse.all)), col = "blue")
lines(rmse.all, col = "blue")
points(rmse.log, col="red")
lines(rmse.log, col = "red",lty = 2)
legend("bottomright", legend=c("Model 1", "Model 2"), col=c("blue", "red"), lty=1:2, cex=0.5)
```

We can now calculate the average root mean sauared error (RMSE) for both of our models' predictions of the 10 folds. The results are below.

```{r echo=FALSE}
label <- c("Model 1", "Model 2")
avg.rmse.all<-round(mean(rmse.all),2)
avg.rmse.log<-round(mean(rmse.log),2)
rmse <- c(avg.rmse.all, avg.rmse.log)
imb.tbl <- cbind(label, rmse)
kable(imb.tbl, caption="Mean RMSE for Models 1 and 2.")
```

# Summary and Conclusions

